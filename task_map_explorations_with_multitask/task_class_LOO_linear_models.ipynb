{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_index(X_without_task_labels):\n",
    "    # when we pass in X for the q2 calculation, we do not have the task labels\n",
    "    # so, let's add in an index for each group of rows (which are part of the same task)\n",
    "\n",
    "    num_rows = len(X_without_task_labels)\n",
    "    num_rows_in_group = num_rows / 10 # because there are 10 tasks\n",
    "    num_groups = (num_rows + num_rows_in_group - 1) // num_rows_in_group  # Calculate the number of groups, rounding up\n",
    "    key_values = np.repeat(np.arange(num_groups), num_rows_in_group)[:num_rows]  # Generate key values for each group\n",
    "    df = X_without_task_labels.copy()\n",
    "    df['task_index'] = key_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x_y(x, y):\n",
    "    if(isinstance(x, pd.Series)):\n",
    "        x = np.asarray(x).reshape(-1, 1)\n",
    "    else:\n",
    "        x = np.asarray(x)\n",
    "    \n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_task_holdout_helper(x_train, x_test, y_train, y_test, estimator):\n",
    "\n",
    "    # some reshaping\n",
    "    x_train_array, y_train_array = reshape_x_y(x_train, y_train)\n",
    "    x_test_array, y_test_array = reshape_x_y(x_test, y_test)\n",
    "\n",
    "    # Fit the model and get the error\n",
    "    fitted_model = estimator.fit(X=x_train_array, y=y_train_array.ravel())\n",
    "    \n",
    "    # save prediction error\n",
    "    prediction = fitted_model.predict(x_test_array)[0]\n",
    "    squared_model_prediction_error = (y_test_array - prediction) ** 2\n",
    "\n",
    "    # save total error for this fold\n",
    "    squared_average_prediction_error = (y_test_array - np.mean(y_train_array)) ** 2\n",
    "\n",
    "    return squared_model_prediction_error, squared_average_prediction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the version of q^2 that holds out EVERYTHING associated with a given task\n",
    "\n",
    "It trains on all task instances from the \"seen\" classes, and it tests on task instances of held-out (unseen) classes.\n",
    "\"\"\"\n",
    "\n",
    "def get_q2(y, x, estimator = LinearRegression(), num_task_holdouts = 1, N_TASK_SAMPLES = 100):\n",
    "    squared_model_prediction_errors = []\n",
    "    squared_average_prediction_errors = []\n",
    "\n",
    "    # generate an index for x and y\n",
    "    x = generate_task_index(pd.DataFrame(x))\n",
    "    y = generate_task_index(pd.DataFrame(y))\n",
    "\n",
    "    num_total_tasks = len(set(x['task_index'].values))\n",
    "\n",
    "    for i in range(num_total_tasks):        \n",
    "        # randomly hold out `num_task_holdouts`\n",
    "        all_possible_task_combos = list(itertools.combinations(set(x['task_index'].values), num_total_tasks - num_task_holdouts))\n",
    "        task_samples = all_possible_task_combos# random.choices(all_possible_task_combos, k=N_TASK_SAMPLES)\n",
    "        \n",
    "        for sample in task_samples:\n",
    "            x_train_tasks = x[x[\"task_index\"].isin(sample)].drop('task_index', axis = 1)\n",
    "            x_test_tasks = x[~x[\"task_index\"].isin(sample)].drop('task_index', axis = 1)\n",
    "\n",
    "            y_train_tasks = y[y[\"task_index\"].isin(sample)].drop('task_index', axis = 1)\n",
    "            y_test_tasks = y[~y[\"task_index\"].isin(sample)].drop('task_index', axis = 1)\n",
    "\n",
    "            # get evaluation score by training on the training tasks and evaluating on the holdout tasks\n",
    "            squared_model_prediction_error, squared_average_prediction_error = q2_task_holdout_helper(x_train_tasks, x_test_tasks, y_train_tasks, y_test_tasks, estimator)\n",
    "\n",
    "            squared_model_prediction_errors.append(squared_model_prediction_error)\n",
    "            squared_average_prediction_errors.append(squared_average_prediction_error)\n",
    "\n",
    "    return 1 - (np.sum(squared_model_prediction_errors) / np.sum(squared_average_prediction_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models for Strong Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_cols_to_use = ['Q1concept_behav', 'Q3type_1_planning', 'Q4type_2_generate',\n",
    "       'Q6type_5_cc', 'Q7type_7_battle', 'Q8type_8_performance',\n",
    "       'Q9divisible_unitary', 'Q10maximizing', 'Q11optimizing',\n",
    "       'Q13outcome_multip', 'Q14sol_scheme_mul', 'Q15dec_verifiability',\n",
    "       'Q16shared_knowledge', 'Q17within_sys_sol', 'Q18ans_recog',\n",
    "       'Q19time_solvability', 'Q20type_3_type_4', 'Q22confl_tradeoffs',\n",
    "       'Q23ss_out_uncert', 'Q24eureka_question', 'Q2intel_manip_1',\n",
    "       'Q21intellective_judg_1', 'Q5creativity_input_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_performance_with_task_cols = pd.read_csv('grouped_performance_with_task_cols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0762575698996276e+24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test LM on the bootstrapped data\n",
    "get_q2(grouped_performance_with_task_cols[\"strong_synergy\"], grouped_performance_with_task_cols[list(task_cols_to_use) + [\"playerCount\", \"Low\", \"Medium\", \"High\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1250760073296147e+24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test LM on the permutation data\n",
    "get_q2(grouped_performance_with_task_cols[\"strong\"], grouped_performance_with_task_cols[list(task_cols_to_use) + [\"playerCount\",  \"Low\", \"Medium\", \"High\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpm_horserace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
