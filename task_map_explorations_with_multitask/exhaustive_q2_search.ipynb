{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e7f6fe-9ca4-40bc-bdfc-4b1ae1f89564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import ast\n",
    "import numpy as np\n",
    "import scipy.stats as stats \n",
    "from scipy.spatial import distance\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os, glob\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import threading\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import queue\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f9d7e-7e0b-499d-bc8a-a713415e56a2",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d2be8b-2b9c-4b87-9781-5c3e2d06d80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_multi_task_data = pd.read_csv('all_multi_task_wave_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2af438-557a-44aa-82f1-d607160ac676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_multi_task_data = full_multi_task_data.rename(columns = {\"task\": \"task_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14997474-4e49-4763-bd56-91a192a5825f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the score to the best score across repeated attempts, in cases where it saved multiple times\n",
    "full_multi_task_data = full_multi_task_data.groupby('stageId').apply(lambda x: x.loc[x['score'].idxmax()]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd051a71-22df-46e9-b5e9-175796abdfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task map\n",
    "task_map = pd.read_csv('task_map.csv')\n",
    "task_map = task_map.rename(columns = {\"task\": \"task_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deeee74f-0f8c-4cfc-bd27-aaee11429564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_name_mapping = {\n",
    "    \"Sudoku\": \"Sudoku\",\n",
    "    \"Moral Reasoning\": \"Moral Reasoning (Disciplinary Action Case)\",\n",
    "    \"Wolf Goat Cabbage\": \"Wolf, goat and cabbage transfer\",\n",
    "    \"Guess the Correlation\": \"Guessing the correlation\",\n",
    "    \"Writing Story\": \"Writing story\",\n",
    "    \"Room Assignment\": \"Room assignment task\",\n",
    "    \"Allocating Resources\": \"Allocating resources to programs\",\n",
    "    \"Divergent Association\": \"Divergent Association Task\",\n",
    "    \"Word Construction\": \"Word construction from a subset of letters\",\n",
    "    \"Whac a Mole\": \"Whac-A-Mole\",\n",
    "    \"Random Dot Motion\": \"Random dot motion\",\n",
    "    \"Recall Association\": \"Recall association\",\n",
    "    \"Recall Word Lists\": \"Recall word lists\",\n",
    "    \"Typing\": \"Typing game\",\n",
    "    \"Unscramble Words\": \"Unscramble words (anagrams)\",\n",
    "    \"WildCam\": \"Wildcam Gorongosa (Zooniverse)\",\n",
    "    \"Advertisement Writing\": \"Advertisement writing\",\n",
    "    \"Putting Food Into Categories\": \"Putting food into categories\"\n",
    "}\n",
    "\n",
    "task_map = task_map.rename(\n",
    "    columns = {\n",
    "        \"Q1concept_behav\": \"Conceptual-Behavioral\",\n",
    "        \"Q3type_1_planning\": \"Type 1 (Planning)\",\n",
    "        \"Q4type_2_generate\": \"Type 2 (Generate)\",\n",
    "        \"Q6type_5_cc\": \"Type 5 (Cognitive Conflict)\",\n",
    "        \"Q7type_7_battle\": \"Type 7 (Battle)\",\n",
    "        \"Q8type_8_performance\": \"Type 8 (Performance)\",\n",
    "        \"Q9divisible_unitary\": \"Divisible-Unitary\",\n",
    "        \"Q10maximizing\": \"Maximizing\",\n",
    "        \"Q11optimizing\": \"Optimizing\",\n",
    "        \"Q13outcome_multip\": \"Outcome Multiplicity\",\n",
    "        \"Q14sol_scheme_mul\": \"Solution Scheme Multiplicity\",\n",
    "        \"Q15dec_verifiability\": \"Decision Verifiability\",\n",
    "        \"Q16shared_knowledge\": \"Shared Knowledge\",\n",
    "        \"Q17within_sys_sol\": \"Within-System Solution\",\n",
    "        \"Q18ans_recog\": \"Answer Recognizability\",\n",
    "        \"Q19time_solvability\": \"Time Solvability\",\n",
    "        \"Q20type_3_type_4\": \"Type 3 and Type 4 (Objective Correctness)\",\n",
    "        \"Q22confl_tradeoffs\": \"Conflicting Tradeoffs\",\n",
    "        \"Q23ss_out_uncert\": \"Solution Scheme Outcome Uncertainty\",\n",
    "        \"Q24eureka_question\": \"Eureka Question\",\n",
    "        \"Q2intel_manip_1\" : \"Intellectual-Manipulative\",\n",
    "        \"Q21intellective_judg_1\" : \"Intellective-Judgmental\",\n",
    "        \"Q5creativity_input_1\" : \"Creativity Input\",\n",
    "        \"Q25_type6_mixed_motive\" : \"Type 6 (Mixed-Motive)\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb10d313-89a3-4da4-b51c-7b4600e6459f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_multi_task_data.loc[:, \"task_name\"] = full_multi_task_data[\"task_name\"].replace(task_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1d7f01-3713-479a-9a5b-a18dd07fff7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_cols_to_use = task_map.drop([\"task_name\", \"Type 6 (Mixed-Motive)\"], axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3094c9b3-70b8-40c8-b477-93569ee4dd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the multi-task data with the task map\n",
    "full_multi_task_data = pd.merge(left = full_multi_task_data, right = task_map, on = \"task_name\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbe7ac5-00cd-4df5-9e5a-5e1272c89031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "communication_features = pd.read_csv(\"full_multi_task_messages_conversation_level.csv\")\n",
    "communication_features = communication_features.rename(columns={\"conversation_num\": \"stageId\"})\n",
    "communication_features.columns\n",
    "communication_features = communication_features.drop(columns = ['speaker_nickname', 'message',\n",
    "       'timestamp', 'message_original', 'message_lower_with_punc'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee8220c-6b7c-4d78-9693-8171a8343994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMS_DVS = [\"turn_taking_index\", \"gini_coefficient_sum_num_messages\", \"sum_num_messages\", \"average_positive_bert\", \"team_burstiness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7872e6-7f59-45df-ba70-c9d3fdc0aa0c",
   "metadata": {},
   "source": [
    "# Final Cleaned Datasets\n",
    "\n",
    "## Task Sets: (1) Wave 1 Only; (2) All 20 Tasks\n",
    "- `team_multi_task_wave1`\n",
    "- `team_multi_task_full`\n",
    "\n",
    "## Communication Features\n",
    "We examine 5 communication features:\n",
    "- Turn-Taking\n",
    "- Gini Coefficient\n",
    "- Total Number of Messages\n",
    "- Positivity\n",
    "- Burstiness\n",
    "\n",
    "When analyzed in the context of the two different task sets, we get:\n",
    "\n",
    "- `team_multi_task_comms_wave1`\n",
    "- `team_multi_task_comms_full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987e1597-2ffe-488c-aee5-749aa9b64ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_multi_task_full = full_multi_task_data[full_multi_task_data[\"playerCount\"]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3733c7-1c27-464d-b691-1f56cb606717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_multi_task_wave1 = team_multi_task_full[team_multi_task_full[\"wave\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04de47b0-8bcb-416b-ae86-5e443bb23b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_multi_task_comms_full = pd.merge(communication_features, team_multi_task_full, on = \"stageId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9e535cf-3682-4f9c-80ee-5691ed00eebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_multi_task_comms_wave1 = pd.merge(communication_features, team_multi_task_wave1, on = \"stageId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c2a0a-b326-4972-9338-4a5a71d99e2d",
   "metadata": {},
   "source": [
    "## Additional Preprocessing\n",
    "- Standardize all task columns\n",
    "- Standardize all dependent variables\n",
    "\n",
    "Note that we should _separately_ preprocess and standardize the interactions / composition variables when we add them in at the regression stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f402d0-1ea9-448f-9e7e-a1a258481dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_to_use = [\"score\"] + list(task_cols_to_use)\n",
    "cols_to_use_with_comms = COMMS_DVS + [\"score\"] + list(task_cols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b70641-4c13-4959-9a56-7b8ae7c3fb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_multi_task_full[cols_to_use] = StandardScaler().fit_transform(team_multi_task_full[cols_to_use])\n",
    "team_multi_task_wave1[cols_to_use] = StandardScaler().fit_transform(team_multi_task_wave1[cols_to_use])\n",
    "team_multi_task_comms_full[cols_to_use_with_comms] = StandardScaler().fit_transform(team_multi_task_comms_full[cols_to_use_with_comms])\n",
    "team_multi_task_comms_wave1[cols_to_use_with_comms] = StandardScaler().fit_transform(team_multi_task_comms_wave1[cols_to_use_with_comms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefd043-0578-42bb-9b6f-cafcbe01b7e0",
   "metadata": {},
   "source": [
    "# Define Functions for Calculating Q^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da353675-33f0-4521-a482-e8a8d017468c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape_x_y(x, y):\n",
    "    if(isinstance(x, pd.Series)):\n",
    "        x = np.asarray(x).reshape(-1, 1)\n",
    "    else:\n",
    "        x = np.asarray(x)\n",
    "    \n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae125f8-7931-465e-a623-11db3f496b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q2_task_holdout_helper(x_train, x_test, y_train, y_test, estimator):\n",
    "    \n",
    "    # some reshaping\n",
    "    x_train_array, y_train_array = reshape_x_y(x_train, y_train)\n",
    "    x_test_array, y_test_array = reshape_x_y(x_test, y_test)\n",
    "\n",
    "    # print(\"Training data: \", pd.DataFrame(x_train_array).head())\n",
    "    # print(\"Testing data: \", pd.DataFrame(x_test_array).head())\n",
    "\n",
    "    # Fit the model and get the error\n",
    "    fitted_model = estimator.fit(X=x_train_array, y=y_train_array.ravel())\n",
    "    \n",
    "    # save prediction error\n",
    "    prediction = fitted_model.predict(x_test_array)\n",
    "\n",
    "    # flatten all arrays\n",
    "    y_test_array = np.asarray(y_test_array).flatten()\n",
    "    prediction = np.asarray(prediction).flatten()\n",
    "\n",
    "    # print(\"y test array\", y_test_array)\n",
    "    # print(\"prediction\", prediction)\n",
    "\n",
    "    squared_model_prediction_error = (y_test_array - prediction) ** 2\n",
    "\n",
    "    # save total error for this fold\n",
    "    squared_average_prediction_error = (y_test_array - np.mean(y_train_array)) ** 2\n",
    "\n",
    "    return squared_model_prediction_error, squared_average_prediction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9bf7403-b350-4363-8d46-146a94d7e9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the version of q^2 that holds out EVERYTHING associated with a given task\n",
    "\n",
    "It trains on all task instances from the \"seen\" classes, and it tests on task instances of held-out (unseen) classes.\n",
    "\n",
    "NOTE: this version of the function assumes that x and y are passed in with a column called \"task_name\"\n",
    "\"\"\"\n",
    "\n",
    "def get_q2(y, x, estimator = Lasso(), num_task_holdouts = 1):\n",
    "\n",
    "    squared_model_prediction_errors = []\n",
    "    squared_average_prediction_errors = []\n",
    "\n",
    "    num_total_tasks = x[\"task_name\"].nunique()\n",
    "\n",
    "    # randomly hold out `num_task_holdouts`\n",
    "    all_possible_task_combos = list(itertools.combinations((x[\"task_name\"].unique()), num_total_tasks - num_task_holdouts))\n",
    "    \n",
    "    for sample in all_possible_task_combos:\n",
    "\n",
    "        # print(\"Sample:\", sample)\n",
    "        # print(\"Held out:\", x[~x[\"task_name\"].isin(sample)][\"task_name\"].unique())\n",
    "\n",
    "        x_train_tasks = x[x[\"task_name\"].isin(sample)].drop(\"task_name\", axis = 1)\n",
    "        x_test_tasks = x[~x[\"task_name\"].isin(sample)].drop(\"task_name\", axis = 1)\n",
    "\n",
    "        y_train_tasks = y[y[\"task_name\"].isin(sample)].drop(\"task_name\", axis = 1)\n",
    "        y_test_tasks = y[~y[\"task_name\"].isin(sample)].drop(\"task_name\", axis = 1)\n",
    "\n",
    "        # get evaluation score by training on the training tasks and evaluating on the holdout tasks\n",
    "        squared_model_prediction_error, squared_average_prediction_error = q2_task_holdout_helper(x_train_tasks, x_test_tasks, y_train_tasks, y_test_tasks, estimator)\n",
    "        \n",
    "        squared_model_prediction_errors.append(squared_model_prediction_error)\n",
    "        squared_average_prediction_errors.append(squared_average_prediction_error)\n",
    "\n",
    "    squared_model_prediction_error = np.asarray(squared_model_prediction_error).flatten()\n",
    "    squared_average_prediction_error = np.asarray(squared_average_prediction_error).flatten()\n",
    "\n",
    "    return 1 - (np.sum(squared_model_prediction_error) / np.sum(squared_average_prediction_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034f19a-e4a3-47b7-9063-c0343c63c16c",
   "metadata": {},
   "source": [
    "# Set up \"Us versus McGrath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33e40f0-b9d4-477b-ac99-d1e20bdb56b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mcgrath_colnames = [col for col in task_map.columns if \"Type\" in col]\n",
    "# remove type 6, as it is not relevant for our data\n",
    "mcgrath_colnames.remove('Type 6 (Mixed-Motive)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17968674-6d06-4dff-b656-b9ace98a936e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mcgrath_categorical(df):\n",
    "    mcgrath_categorical_buckets = {}\n",
    "    \n",
    "    # first, convert everything into one of mcgrath's categories\n",
    "    for i in range(len(df)):\n",
    "        task_vec_mcgrath = df[mcgrath_colnames].iloc[i][1:]\n",
    "        task_name = df.iloc[i][\"task_name\"]\n",
    "        task_type = task_vec_mcgrath.idxmax()\n",
    "        type_val = task_vec_mcgrath[task_type]\n",
    "        if task_type == \"Type 3 and Type 4 (Objective Correctness)\":\n",
    "            task_type = \"Type 3 (Intellective)\" if type_val > 0.5 else \"Type 4 (Decision-Making)\"\n",
    "\n",
    "        mcgrath_categorical_buckets[task_name] = task_type\n",
    "        \n",
    "    mcgrath_df = pd.DataFrame({\n",
    "        \"task_name\": mcgrath_categorical_buckets.keys(),\n",
    "        \"mcgrath_category\": mcgrath_categorical_buckets.values()\n",
    "    })\n",
    "\n",
    "    mcgrath_df_categorical = pd.concat([mcgrath_df[\"task_name\"], pd.get_dummies(mcgrath_df[\"mcgrath_category\"], dtype= int).add_suffix('_cat')], axis = 1)\n",
    "\n",
    "    mcgrath_categorical = list(mcgrath_df_categorical.columns)\n",
    "    mcgrath_categorical.remove(\"task_name\")\n",
    "    \n",
    "    # after calculating the categories, return the dataframe\n",
    "    return (df.merge(mcgrath_df_categorical, on = \"task_name\"), mcgrath_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "184742d1-277b-47e1-acf8-0d76f7c4ad26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OUR FOUR DATASETS ARE:\n",
    "# team_multi_task_full, team_multi_task_wave1\n",
    "# team_multi_task_comms_full, team_multi_task_comms_wave1\n",
    "\n",
    "def get_mcgrath_comparisons(datasets, dvs):\n",
    "    \n",
    "    comparison_dict_list = [{} for i in range(len(datasets))]\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        comparison_dict = comparison_dict_list[i]\n",
    "        \n",
    "        dataset, mcgrath_categorical = get_mcgrath_categorical(dataset)\n",
    "\n",
    "        for dv in dvs:\n",
    "            comparison_dict[dv] = {}\n",
    "            comparison_dict[dv][\"mcgrath_continuous\"] = get_q2(dataset[[dv, \"task_name\"]], dataset[mcgrath_colnames + [\"playerCount\", \"Low\", \"Medium\", \"task_name\"]], estimator = LinearRegression())\n",
    "            comparison_dict[dv][\"mcgrath_categorical\"] = get_q2(dataset[[dv, \"task_name\"]], dataset[mcgrath_categorical + [\"playerCount\", \"Low\", \"Medium\", \"task_name\"]], estimator = LinearRegression())\n",
    "            comparison_dict[dv][\"all_features\"] = get_q2(dataset[[dv, \"task_name\"]], dataset[list(task_cols_to_use) + [\"playerCount\", \"Low\", \"Medium\", \"task_name\"]], estimator = LinearRegression())\n",
    "            \n",
    "    return comparison_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba16db-49fa-42f4-95c9-172dc7fc299e",
   "metadata": {},
   "source": [
    "Our dictionaries of looking at McGrath versus the rest:\n",
    "1. `mcgrath_comparisons_full`\n",
    "2. `mcgrath_comparisons_wave1`\n",
    "3. `mcgrath_comparisons_conv_full`\n",
    "4. `mcgrath_comparisons_conv_wave1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9813c3fe-1e2d-4102-b3bd-bf2356f150cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mcgrath_comparisons_full, mcgrath_comparisons_wave1 = get_mcgrath_comparisons([team_multi_task_full, team_multi_task_wave1], [\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae29895c-5fa5-4819-bb7e-e6a51ff3cf90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mcgrath_comparisons_conv_full, mcgrath_comparisons_conv_wave1 = get_mcgrath_comparisons([team_multi_task_comms_full, team_multi_task_comms_wave1], [\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1727ec94-5548-4946-bc58-5c7f8e4e5efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': {'mcgrath_continuous': 0.12797385310435472,\n",
       "  'mcgrath_categorical': 0.20664078198140312,\n",
       "  'all_features': -7.386896991380263e+23}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of looking at the dictionary\n",
    "mcgrath_comparisons_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fe0df-fda8-4f2c-ba1c-4308dbe3e6b7",
   "metadata": {},
   "source": [
    "# Exhaustive Search Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b645c942-269b-4be7-863e-40a105a85dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_combination(task_col_combo, dataset, dv, filename):\n",
    "    return get_q2(\n",
    "                dataset[[dv, \"task_name\"]],\n",
    "                dataset[list(task_col_combo) + [\"playerCount\", \"Low\", \"Medium\", \"task_name\"]],\n",
    "                estimator = LinearRegression() ## get_q2 defaults to LASSO, so let's run this with OLS\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "function: parallel_q2\n",
    "---\n",
    "This is the function that (in parallel) gets the q^2 values of each\n",
    "of the possible combinations / ways of selecting task columns.\n",
    "\n",
    "@dataset: the dataset that we are using for the prediction\n",
    "@dv: the name of the dependent variable. We expect this to be a column in the dataset.\n",
    "@filename: the name of the output file (as we finish processing the combinations, the results will be written to this file).\n",
    "@column_choice_combinations: the list of all possible column choice combinations.\n",
    "\"\"\"\n",
    "def parallel_q2(dataset, dv, filename, column_choice_combinations, results, lock):\n",
    "    num_threads = multiprocessing.cpu_count()  # Get as many processes as CPU's\n",
    "    assert len(results) == 0  # Assert that we start out with no results\n",
    "    \n",
    "    with tqdm(total=len(column_choice_combinations)) as pbar:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            def wrapper(task_col_combo):\n",
    "                try:\n",
    "                    q2 = process_combination(task_col_combo, dataset, dv, filename)                    \n",
    "                    if isinstance(q2, (int, float)):  # Ensure q2 is a valid number\n",
    "                        result_to_append = (str(task_col_combo), q2)\n",
    "                        assert(len(result_to_append) == 2) # assert that there are exactly 2 elements\n",
    "                        \n",
    "                        with lock: # do this with a lock\n",
    "                            results.append(result_to_append)\n",
    "                            output_filename = str(len(task_col_combo)) + \"_\" + dv + \"_\" + filename                    \n",
    "                            df_results = pd.DataFrame(results, columns=[\"selected_task_cols\", \"q2\"]).drop_duplicates()\n",
    "                            df_results.to_csv(output_filename, index=False)\n",
    "                except Exception as e:\n",
    "                    print(results)\n",
    "                    print(f\"DataFrame shape: {df_results.shape}\")\n",
    "                    print(f\"Error processing {task_col_combo}: {e}\")\n",
    "\n",
    "            # Map the process function to each combination\n",
    "            futures = [executor.submit(wrapper, combo) for combo in column_choice_combinations]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1907f4-2196-4f0b-88df-a1d3b8f9b332",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Call the Exhaustive Search Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "799eeb6b-e7ec-4437-bc5d-91e740b9b041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_parallel_q2(dataset, dv):\n",
    "    \n",
    "    # start with the number of mcgrath columns\n",
    "    num_mcgrath_columns = len(mcgrath_colnames)\n",
    "\n",
    "    for num_cols in range(num_mcgrath_columns, len(set(dataset[\"task_name\"]))+1):\n",
    "        print(\"Running exhaustive search for \" + str(num_cols) + \" columns...\")\n",
    "        \n",
    "        column_choice_combinations = list(itertools.combinations(task_cols_to_use, num_cols))\n",
    "        results = []\n",
    "        lock = threading.Lock()\n",
    "\n",
    "        # call the parallel q2\n",
    "        parallel_q2(dataset = dataset , dv = dv, filename = \"q2_OLS_from_diff_task_cols.csv\", column_choice_combinations = column_choice_combinations, results = results, lock = lock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd82f3-78a8-494b-8e52-65c2ef5daa0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running exhaustive search for 6 columns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 10281/100947 [31:46<5:51:58,  4.29it/s]"
     ]
    }
   ],
   "source": [
    "call_parallel_q2(team_multi_task_wave1, \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b674f7-dd42-470c-a1b1-43c11db922ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0cd68-2724-4db3-a1ef-622ffc636fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469478c-eaad-4458-a244-74897182f31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "tpm_horserace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
