{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x_y(x, y):\n",
    "    if(isinstance(x, pd.Series)):\n",
    "        x = np.asarray(x).reshape(-1, 1)\n",
    "    else:\n",
    "        x = np.asarray(x)\n",
    "    \n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('x_tasks.csv')\n",
    "y = pd.read_csv('y_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 100. 100. 100. 100. 100. 100.  60. 100. 100. 100. 100.   0.   0.\n",
      "   0.  43. 100. 100. 100.  78.   0. 100.  43. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100. 100. 100.   0. 100. 100. 100. 100.   0. 100.\n",
      "   0. 100.   0. 100.  43. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.   0. 100. 100.\n",
      " 100.   0. 100. 100. 100. 100. 100. 100. 100.  43. 100. 100. 100. 100.\n",
      "  60. 100. 100. 100.   0. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100.   0. 100. 100.  33. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100.   0. 100.   0. 100.  60.   0. 100.  43. 100. 100. 100.   0.\n",
      "  43. 100. 100.  33. 100.  43. 100. 100. 100. 100. 100.   0. 100. 100.\n",
      " 100. 100. 100. 100. 100. 100. 100. 100.   0. 100. 100. 100. 100.   0.\n",
      " 100. 100. 100.  78.   0. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100.  78. 100.   0. 100. 100. 100. 100. 100. 100. 100.   0.  60. 100.\n",
      " 100.  43. 100.   0. 100.  60.   0. 100. 100. 100. 100. 100. 100.]\n",
      "69.48025710532349\n",
      "[100.0343015   92.51633704 106.90730165 101.29315357  95.93371309\n",
      "  99.31481994  94.48037255  97.62881926 104.66906779 102.96876898\n",
      " 102.3797203   95.68706616  92.18982455  90.78217003  89.33251029\n",
      " 100.32822559  88.82580747 100.32822559 104.66906779  99.33047424\n",
      "  95.04713882 102.68658634  94.5065678  102.3797203  102.46981547\n",
      " 102.46981547  91.99638092 104.86235575  91.99638092  96.07092975\n",
      "  89.33251029 103.60334801  94.21392351  97.41084788  97.41084788\n",
      "  97.18097938  98.39805828 100.97853822  94.48037255 100.4561018\n",
      "  90.83952114 102.58339355  94.80808553  93.47990885  94.21392351\n",
      " 102.41238799  99.79788418  92.53710761  95.93371309  97.62881926\n",
      "  88.11543139  96.07092975 103.60334801  93.47990885 107.57590454\n",
      " 104.86235575  95.83067596 102.58339355  96.07092975 103.88018233\n",
      " 106.90730165  98.01148234 107.57590454  98.8510908   97.79591197\n",
      " 104.68336591 107.13062134 102.72851519 105.58183731 100.38828904\n",
      "  91.65692648  93.67064015 100.4561018  100.38828904  97.79591197\n",
      " 105.58183731  91.97305368 103.81876271 100.38828904  97.18097938\n",
      "  90.78217003 102.3797203   94.48037255  95.68706616  99.79788418\n",
      " 107.57590454  93.03613749 100.0343015   95.83067596 102.41238799\n",
      "  97.13521406 104.86235575 101.29315357  97.62227044 100.97853822\n",
      "  98.39805828 102.68658634  95.68706616 100.4561018   97.26723808\n",
      "  91.97305368  91.33312634  92.53710761  91.33312634 102.46981547\n",
      " 100.97853822  94.80808553  89.33251029  95.04713882  95.83067596\n",
      "  94.21392351  97.62227044 102.68658634  97.13521406  98.01148234\n",
      "  90.79255532  97.26723808  94.21392351  97.62227044 104.68336591\n",
      "  96.01861561  95.93371309  88.82580747  97.79591197 100.0343015\n",
      "  88.82580747  91.65692648  98.39805828  90.79255532  97.18097938\n",
      "  88.11543139  93.47990885  99.33047424 101.29315357  96.01861561\n",
      "  96.21845239  88.11543139  92.18982455 103.88018233  98.01148234\n",
      "  99.31481994 107.13062134  93.67064015 102.96876898 103.81876271\n",
      "  90.83952114  96.21845239  97.13521406  93.03613749 101.57149974\n",
      "  90.83952114 102.41238799  99.31481994  90.78217003  92.51633704\n",
      " 101.57149974  99.33047424  91.33312634  92.18982455 103.60334801\n",
      "  92.51633704  98.8510908   90.79255532  93.67064015 106.90730165\n",
      "  97.26723808 103.81876271 102.58339355 103.88018233  96.21845239\n",
      " 104.68336591 102.72851519  93.03613749 100.32822559  98.8510908\n",
      "  94.21392351 101.57149974 105.58183731  91.99638092 102.72851519\n",
      "  91.65692648 107.13062134  99.79788418 104.66906779  97.62881926\n",
      "  92.53710761  94.21392351  94.5065678   94.5065678  102.96876898\n",
      "  95.04713882  91.97305368  96.01861561  97.41084788  94.80808553]\n",
      "0.024504175612534373\n"
     ]
    }
   ],
   "source": [
    "squared_model_prediction_errors = []\n",
    "squared_average_prediction_errors = []\n",
    "\n",
    "all_tasks = set(x[\"task_name\"])\n",
    "\n",
    "cur_task = \"Wolf, goat and cabbage transfer\"\n",
    "training_tasks = [t for t in all_tasks if t != cur_task] # the 9 training tasks\n",
    "\n",
    "x_train = x[x[\"task_name\"].isin(training_tasks)].drop(\"task_name\", axis = 1)\n",
    "x_test = x[~x[\"task_name\"].isin(training_tasks)].drop(\"task_name\", axis = 1)\n",
    "\n",
    "y_train = y[y[\"task_name\"].isin(training_tasks)].drop(\"task_name\", axis = 1)\n",
    "y_test = y[~y[\"task_name\"].isin(training_tasks)].drop(\"task_name\", axis = 1)\n",
    "\n",
    "# get evaluation score by training on the training tasks and evaluating on the holdout tasks\n",
    "# some reshaping\n",
    "x_train_array, y_train_array = reshape_x_y(x_train, y_train)\n",
    "x_test_array, y_test_array = reshape_x_y(x_test, y_test)\n",
    "\n",
    "# Fit the model and get the error\n",
    "fitted_model = Lasso().fit(X=x_train_array, y=y_train_array)\n",
    "prediction = fitted_model.predict(x_test_array)\n",
    "\n",
    "# results = sm.OLS(y_train_array, x_train_array).fit()\n",
    "# prediction = results.predict(x_test_array)\n",
    "\n",
    "# save prediction error\n",
    "# fitted_model = LinearRegression().fit(X=np.asarray(x_train_array), y=np.asarray(y_train_array))\n",
    "# prediction = fitted_model.predict(np.asarray(x_test_array))\n",
    "\n",
    "# flatten all arrays\n",
    "y_test_array = np.asarray(y_test_array).flatten()\n",
    "prediction = np.asarray(prediction).flatten()\n",
    "\n",
    "print(y_test_array)\n",
    "print(np.mean(y_train_array))\n",
    "print(prediction)\n",
    "\n",
    "squared_model_prediction_error = (y_test_array - prediction) ** 2\n",
    "\n",
    "# save total error for this fold\n",
    "squared_average_prediction_error = (y_test_array - np.mean(y_train_array)) ** 2\n",
    "\n",
    "squared_model_prediction_errors.append(squared_model_prediction_error)\n",
    "squared_average_prediction_errors.append(squared_average_prediction_error)\n",
    "\n",
    "squared_model_prediction_error = np.asarray(squared_model_prediction_error).flatten()\n",
    "squared_average_prediction_error = np.asarray(squared_average_prediction_error).flatten()\n",
    "\n",
    "q2 = 1 - (np.sum(squared_model_prediction_error) / np.sum(squared_average_prediction_error))\n",
    "print(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 100., 100., 100., 100., 100.,  60., 100., 100., 100.,\n",
       "       100.,   0.,   0.,   0.,  43., 100., 100., 100.,  78.,   0., 100.,\n",
       "        43., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100.,   0., 100., 100., 100., 100.,   0., 100.,   0., 100.,\n",
       "         0., 100.,  43., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100.,   0., 100., 100., 100.,   0., 100., 100., 100., 100., 100.,\n",
       "       100., 100.,  43., 100., 100., 100., 100.,  60., 100., 100., 100.,\n",
       "         0., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "         0., 100., 100.,  33., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100.,   0., 100.,   0., 100.,  60.,   0., 100.,\n",
       "        43., 100., 100., 100.,   0.,  43., 100., 100.,  33., 100.,  43.,\n",
       "       100., 100., 100., 100., 100.,   0., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100.,   0., 100., 100., 100., 100.,   0.,\n",
       "       100., 100., 100.,  78.,   0., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100.,  78., 100.,   0., 100., 100., 100., 100.,\n",
       "       100., 100., 100.,   0.,  60., 100., 100.,  43., 100.,   0., 100.,\n",
       "        60.,   0., 100., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.13910666e+13, 2.67522437e+13, 2.09025294e+13, 1.96015922e+13,\n",
       "       2.03995244e+13, 2.31897681e+13, 2.46239661e+13, 2.16582759e+13,\n",
       "       2.35789935e+13, 2.35073996e+13, 2.14488803e+13, 2.58212082e+13,\n",
       "       2.54282870e+13, 2.99547445e+13, 2.62087433e+13, 2.38875433e+13,\n",
       "       2.58598557e+13, 2.38875433e+13, 2.35789935e+13, 2.36542953e+13,\n",
       "       2.46478307e+13, 2.05610332e+13, 2.75730378e+13, 2.14488803e+13,\n",
       "       2.09613458e+13, 2.09613458e+13, 2.00699606e+13, 2.40784603e+13,\n",
       "       2.00699606e+13, 2.29712907e+13, 2.62087433e+13, 2.10090751e+13,\n",
       "       2.29749865e+13, 2.49930226e+13, 2.49930226e+13, 2.39187994e+13,\n",
       "       2.27417262e+13, 2.26866055e+13, 2.46239661e+13, 2.10403311e+13,\n",
       "       2.57808704e+13, 1.95740319e+13, 2.30134887e+13, 2.05418671e+13,\n",
       "       2.29749865e+13, 2.11092197e+13, 1.95795755e+13, 2.20036132e+13,\n",
       "       2.03995244e+13, 2.16582759e+13, 2.73858165e+13, 2.29712907e+13,\n",
       "       2.10090751e+13, 2.05418671e+13, 1.99889698e+13, 2.40784603e+13,\n",
       "       2.42713827e+13, 1.95740319e+13, 2.29712907e+13, 2.02837394e+13,\n",
       "       2.09025294e+13, 2.17427926e+13, 1.99889698e+13, 1.92940451e+13,\n",
       "       1.92086711e+13, 2.21190952e+13, 2.12394847e+13, 2.48074916e+13,\n",
       "       2.22797589e+13, 2.35625203e+13, 2.21303277e+13, 2.20513424e+13,\n",
       "       2.10403311e+13, 2.35625203e+13, 1.92086711e+13, 2.22797589e+13,\n",
       "       2.58285996e+13, 1.86843369e+13, 2.35625203e+13, 2.39187994e+13,\n",
       "       2.99547445e+13, 2.14488803e+13, 2.46239661e+13, 2.58212082e+13,\n",
       "       1.95795755e+13, 1.99889698e+13, 2.85756671e+13, 2.13910666e+13,\n",
       "       2.42713827e+13, 2.11092197e+13, 2.27839241e+13, 2.40784603e+13,\n",
       "       1.96015922e+13, 2.09210080e+13, 2.26866055e+13, 2.27417262e+13,\n",
       "       2.05610332e+13, 2.58212082e+13, 2.10403311e+13, 2.65428480e+13,\n",
       "       2.58285996e+13, 2.46552222e+13, 2.20036132e+13, 2.46552222e+13,\n",
       "       2.09613458e+13, 2.26866055e+13, 2.30134887e+13, 2.62087433e+13,\n",
       "       2.46478307e+13, 2.42713827e+13, 2.29749865e+13, 2.09210080e+13,\n",
       "       2.05610332e+13, 2.27839241e+13, 2.17427926e+13, 2.75804292e+13,\n",
       "       2.65428480e+13, 2.29749865e+13, 2.09210080e+13, 2.21190952e+13,\n",
       "       2.10991476e+13, 2.03995244e+13, 2.58598557e+13, 1.92086711e+13,\n",
       "       2.13910666e+13, 2.58598557e+13, 2.21303277e+13, 2.27417262e+13,\n",
       "       2.75804292e+13, 2.39187994e+13, 2.73858165e+13, 2.05418671e+13,\n",
       "       2.36542953e+13, 1.96015922e+13, 2.10991476e+13, 2.23358823e+13,\n",
       "       2.73858165e+13, 2.54282870e+13, 2.02837394e+13, 2.17427926e+13,\n",
       "       2.31897681e+13, 2.12394847e+13, 2.20513424e+13, 2.35073996e+13,\n",
       "       1.86843369e+13, 2.57808704e+13, 2.23358823e+13, 2.27839241e+13,\n",
       "       2.85756671e+13, 2.56595418e+13, 2.57808704e+13, 2.11092197e+13,\n",
       "       2.31897681e+13, 2.99547445e+13, 2.67522437e+13, 2.56595418e+13,\n",
       "       2.36542953e+13, 2.46552222e+13, 2.54282870e+13, 2.10090751e+13,\n",
       "       2.67522437e+13, 1.92940451e+13, 2.75804292e+13, 2.20513424e+13,\n",
       "       2.09025294e+13, 2.65428480e+13, 1.86843369e+13, 1.95740319e+13,\n",
       "       2.02837394e+13, 2.23358823e+13, 2.21190952e+13, 2.48074916e+13,\n",
       "       2.85756671e+13, 2.38875433e+13, 1.92940451e+13, 2.29749865e+13,\n",
       "       2.56595418e+13, 2.22797589e+13, 2.00699606e+13, 2.48074916e+13,\n",
       "       2.21303277e+13, 2.12394847e+13, 1.95795755e+13, 2.35789935e+13,\n",
       "       2.16582759e+13, 2.20036132e+13, 2.29749865e+13, 2.75730378e+13,\n",
       "       2.75730378e+13, 2.35073996e+13, 2.46478307e+13, 2.58285996e+13,\n",
       "       2.10991476e+13, 2.49930226e+13, 2.30134887e+13])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpm_horserace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
